{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nayak, Anil Kumar\n",
    "# 1001-396-015\n",
    "# 2017-03-20\n",
    "# Assignment_03_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This program is used for training phase of face detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import timeit\n",
    "import scipy.misc as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_rectangular_filters(N=24,min_max_size=10, max_max_size=16):\n",
    "    \"\"\" This function uses the five base rectangular filters and\n",
    "    creates all the possible different size and position filters\n",
    "    inside an N by N area. The output of this function is a list of\n",
    "    dictionaries. Each dictionary represents a rectangular filter\n",
    "    at a particular position (x,y) and a particular width and Height.\n",
    "    Note: the value of threshold for all the filters is set to zero.\n",
    "    This value is just a place holder for use in task 2. The value\n",
    "    of alpha for all the filters is set to 1. This is just a place\n",
    "    holder to be used for Adaboost in task 2.\n",
    "    Farhad Kamangar Feb. 13, 2017\"\"\"\n",
    "\n",
    "    FeatureTypes = [(1, 2),(2, 1),(1, 3),(3, 1),(2, 2)]\n",
    "    rectangular_filters = []\n",
    "    for current_feature in FeatureTypes:\n",
    "        for height in range(current_feature[0], N+1, current_feature[0]):\n",
    "            for width in range(current_feature[1], N+1, current_feature[1]):\n",
    "                #if max(height,width) >= min_max_size and max(height,width) <= max_max_size:\n",
    "                for x in range(N - width+1):\n",
    "                    for y in range(N - height+1):\n",
    "                        temp_dict={\"type\":current_feature,\"position\":(x,y),\"width\":width,\"height\":height,\"threshold\":0,\n",
    "                                   \"alpha\":1,\"error\":0,\"selected\":0,\"pred_face\":0,\"pred_non_face\":0,\"number_face\":0,\n",
    "                                   \"number_non_face\":0,'miss_clasf_face':0,'miss_clasf_non_face':0}\n",
    "                        rectangular_filters.append(temp_dict)\n",
    "    return rectangular_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_min_max_threshold(w_c,h_c,m,n):\n",
    "    pixels_in_section = (w_c / m) * (h_c / n)\n",
    "    min_threshold = 0\n",
    "    max_threshold = 0\n",
    "    if (m == 2 and n == 1) or (m == 1 and n == 2):\n",
    "        min_threshold = -pixels_in_section\n",
    "        max_threshold = pixels_in_section\n",
    "    elif (m == 3 and n == 1):\n",
    "        min_threshold = -1 * 2 * pixels_in_section\n",
    "        max_threshold = pixels_in_section\n",
    "    elif (m == 1 and n == 3):\n",
    "        min_threshold = -pixels_in_section\n",
    "        max_threshold = 2 * pixels_in_section\n",
    "    elif (m == 2 and n == 2):\n",
    "        min_threshold = -1 * 2 * pixels_in_section\n",
    "        max_threshold = 2 * pixels_in_section\n",
    "\n",
    "    return min_threshold,max_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def all_images_pixel(directory_name, convert_flag):\n",
    "    pixel_all_image_in_directory = []\n",
    "    all_image_names = os.listdir(directory_name)\n",
    "    # data = np.array([cv2.imread(name) for name in os.listdir(directory_name+\"/\")], dtype=np.float64)\n",
    "    # print(data(0))\n",
    "    for image_name in all_image_names:\n",
    "        image = cv2.imread(directory_name + \"/\" + image_name);\n",
    "\n",
    "        if convert_flag == 1:\n",
    "            image = cv2.resize(image, None, fx=24, fy=24, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # print(gray_image.shape)\n",
    "        images = {}\n",
    "        images['image'] = gray_image / 255\n",
    "        pixel_all_image_in_directory.append(images)\n",
    "\n",
    "    return pixel_all_image_in_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def each_classifier_size_net_value(image, width, height, rows, cols):\n",
    "    value = 0\n",
    "\n",
    "    if rows == 1 and cols == 2:\n",
    "        section1 = -np.sum(image[0: int(width / cols), 0:height])\n",
    "        section2 = np.sum(image[int(width / cols):width, 0:height])\n",
    "        value = section1 + section2\n",
    "    elif rows == 2 and cols == 1:\n",
    "        section1 = -np.sum(image[0:width, 0:int(height / rows)])\n",
    "        section2 = np.sum(image[0:width, int(height / rows):height])\n",
    "        value = section1 + section2\n",
    "    elif rows == 3 and cols == 1:\n",
    "        section1 = -np.sum(image[0:width, 0:int(height / 3)])\n",
    "        section2 = np.sum(image[0:width, int(height / 3):int(height * (2 / 3))])\n",
    "        section3 = -np.sum(image[0:width, int(height * (2 / 3)):height])\n",
    "        value = section1 + section2 + section3\n",
    "    elif rows == 1 and cols == 3:\n",
    "        #print(width,height,cols,rows)\n",
    "        section1 = np.sum(image[0:int(width / 3), 0:height])\n",
    "        section2 = -np.sum(image[int(width / 3):int(width * (2 / 3)), 0:height])\n",
    "        section3 = np.sum(image[int(width * (2 / 3)):width, 0:height])\n",
    "        value = section1 + section2 + section3\n",
    "    elif rows == 2 and cols == 2:\n",
    "        section1 = -np.sum(image[0:int(width / 2), 0:int(height / 2)])\n",
    "        section2 = np.sum(image[int(width / 2):width, 0:int(height / 2)])\n",
    "        section3 = -np.sum(image[0:int(width / 2), int(height / 2):height])\n",
    "        section4 = np.sum(image[int(width / 2):width, int(height / 2):height])\n",
    "        value = section1 + section2 + section3 + section4\n",
    "\n",
    "    return value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_json(classifers):\n",
    "    with open('Nayak_03_02.json','w') as file:\n",
    "        json.dump(classifers,file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_alpha_for_classifier(error_rate_for_classifier):\n",
    "    alpha_for_classifier = 0\n",
    "    if error_rate_for_classifier != 0:\n",
    "        alpha_for_classifier = (np.log(((1-error_rate_for_classifier)/error_rate_for_classifier)))/2\n",
    "    return alpha_for_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training Face Detection through adaboosting\n",
    "# traing_flag = 1 if the classification will be trained for the actual training data\n",
    "# traing_flag = -1 if the classification is carried out with the other than the actual data for misclassification\n",
    "\n",
    "\n",
    "def train_adaboost_face_detection(faces, non_faces, list_of_rectrangle_templates, traing_flag,number_of_classifier_to_select):\n",
    "    number_of_faces = np.size(faces)\n",
    "    number_of_non_faces = np.size(non_faces)\n",
    "    total_images = number_of_faces + number_of_non_faces\n",
    "\n",
    "    y_faces = np.ones(number_of_faces)\n",
    "    y_non_faces = np.zeros(number_of_non_faces)\n",
    "    y_non_faces.fill(-1)\n",
    "\n",
    "    weights_f = np.zeros(number_of_faces)\n",
    "    weights_n_f = np.zeros(number_of_non_faces)\n",
    "    weights_f.fill(1 / total_images)\n",
    "    weights_n_f.fill(1 / total_images)\n",
    "\n",
    "    strong_classifiers = []\n",
    "    count_class = 0\n",
    "    for i in range(number_of_classifier_to_select):\n",
    "        list_of_rectrangle_templates.sort(key=operator.itemgetter('error'), reverse=False)\n",
    "\n",
    "        if i >= 1:\n",
    "            strong_classifier = {}\n",
    "            # Select the least error classifier\n",
    "            selected_classifier = list_of_rectrangle_templates[0]\n",
    "            list_of_rectrangle_templates = list_of_rectrangle_templates[1:]\n",
    "\n",
    "            print(\"Selected One Classifier\", selected_classifier['type'],\n",
    "                  selected_classifier['position'], selected_classifier['width'], selected_classifier['height'],\n",
    "                  selected_classifier['alpha'], selected_classifier['threshold'])\n",
    "\n",
    "            # calculate weight\n",
    "            alpha = selected_classifier['alpha']\n",
    "            pred_face = selected_classifier['pred_face']\n",
    "            pred_non_face = selected_classifier['pred_non_face']\n",
    "            \n",
    "            e = weights_f * np.exp((-1*(y_faces * alpha * pred_face)))\n",
    "            e1 = weights_n_f * np.exp((-1*(y_non_faces * alpha * pred_non_face)))\n",
    "\n",
    "            weights_f = e / (np.sum(e) + np.sum(e1))\n",
    "            weights_n_f = e1 / (np.sum(e) + np.sum(e1))\n",
    "\n",
    "            strong_classifier['type'] = selected_classifier['type']\n",
    "            strong_classifier['position'] = selected_classifier['position']\n",
    "            strong_classifier['alpha'] = selected_classifier['alpha']\n",
    "            strong_classifier['width'] = selected_classifier['width']\n",
    "            strong_classifier['height'] = selected_classifier['height']\n",
    "            strong_classifier['threshold'] = selected_classifier['threshold']\n",
    "            strong_classifier['error'] = selected_classifier['error']\n",
    "            strong_classifiers.append(strong_classifier)\n",
    "\n",
    "        for classifier in list_of_rectrangle_templates:\n",
    "            selected = classifier['selected']\n",
    "\n",
    "            # Classifier is already selected\n",
    "            if selected == 1:\n",
    "                continue\n",
    "\n",
    "            # \"type\":current_feature,\"position\":(x,y),\"width\":width,\"height\":height,\"threshold\":0,\"alpha\":1\n",
    "            # print(classifier)\n",
    "            # Classifier Type\n",
    "            n, m = classifier['type']\n",
    "            # position x and y\n",
    "            x, y = classifier['position']\n",
    "            # width w and height h\n",
    "            w_c = classifier['width']\n",
    "            h_c = classifier['height']\n",
    "            # threshold\n",
    "            # error\n",
    "            # alpha\n",
    "\n",
    "\n",
    "            if i == 0:\n",
    "                count_class = count_class + 1\n",
    "                # Take one classifier and visit all the images and find the values\n",
    "                classifier['number_face'] = number_of_faces\n",
    "                values_faces = np.zeros(number_of_faces)\n",
    "                index = 0\n",
    "                for face in faces:\n",
    "                    image = face['image']\n",
    "                    image_slice = image[x:x + w_c, y:y + h_c]\n",
    "                    # print(\"Image Shape : \",image_slice.shape,x,y)\n",
    "                    # accumulating all the values of one classifier for all the images\n",
    "                    try:\n",
    "                        value = each_classifier_size_net_value(image_slice, w_c, h_c, n, m)\n",
    "                        values_faces[index] = value\n",
    "                    except ValueError:\n",
    "                        ''\n",
    "                        # print(\"index : value \",index,value,w_c,h_c,n,m)\n",
    "                    index = index + 1\n",
    "                #print(\"values_faces\",values_faces)\n",
    "                # classifier['values_face'] = values_faces\n",
    "\n",
    "                classifier['number_non_face'] = number_of_non_faces\n",
    "                values_non_faces = np.zeros(number_of_non_faces)\n",
    "                index = 0\n",
    "                for non_face in non_faces:\n",
    "                    image = non_face['image']\n",
    "                    image_slice = image[x:x + w_c, y:y + h_c]\n",
    "                    # print(\"Image Shape : \",image_slice.shape,x,y)\n",
    "                    try:\n",
    "                        # accumulating all the values of one classifier for all the images\n",
    "                        value = each_classifier_size_net_value(image_slice, w_c, h_c, n, m)\n",
    "                        values_non_faces[index] = value\n",
    "                    except ValueError:\n",
    "                        ''\n",
    "                        # print(\"1 index : value \",index,value,w_c,h_c,n,m)\n",
    "                    index = index + 1\n",
    "                #print(\"values_non_faces\",values_non_faces)\n",
    "                # classifier['values_non_face'] = values_non_faces\n",
    "\n",
    "                error = 0\n",
    "                threshold = 0\n",
    "                incorrect_face_classified = ''\n",
    "                incorrect_non_face_classified = ''\n",
    "                pred_face = ''\n",
    "                pred_non_face = ''\n",
    "\n",
    "                #print(w_c, h_c, m, n)\n",
    "                min_threshold, max_threshold = define_min_max_threshold(w_c, h_c, m, n)\n",
    "                #print(min_threshold, max_threshold)\n",
    "                threshold_range = np.linspace(min_threshold, max_threshold, 2);\n",
    "                #print(threshold_range)\n",
    "                #error_per_th = np.zeros(20);\n",
    "                #error_count = 0;\n",
    "                for th in threshold_range:\n",
    "                    correct_v_f = np.where(values_faces >= th, 1, -1)\n",
    "                    correct_v_n_f = np.where(values_non_faces >= th, 1, -1)\n",
    "\n",
    "                    incorrect_face_classify = np.where(y_faces != correct_v_f)\n",
    "                    incorrect_non_face_classify = np.where(y_non_faces != correct_v_n_f)\n",
    "\n",
    "                    incorrect_weights_f = np.take(weights_f, incorrect_face_classify)\n",
    "                    incorrect_weights_n_f = np.take(weights_n_f, incorrect_non_face_classify)\n",
    "\n",
    "                    total_incorrectly_classified_weights = sum(incorrect_weights_f[0]) + sum(incorrect_weights_n_f[0])\n",
    "                    total_incorrectly_classified_weights = abs(total_incorrectly_classified_weights-0.5)\n",
    "\n",
    "                    if error < total_incorrectly_classified_weights:\n",
    "                        error = total_incorrectly_classified_weights\n",
    "                        threshold = th\n",
    "                        incorrect_face_classified = incorrect_face_classify\n",
    "                        incorrect_non_face_classified = incorrect_non_face_classify\n",
    "                        pred_face = correct_v_f\n",
    "                        pred_non_face = correct_v_n_f\n",
    "\n",
    "                classifier['error'] = error\n",
    "                classifier['threshold'] = threshold\n",
    "                classifier['miss_clasf_face'] = incorrect_face_classified\n",
    "                classifier['miss_clasf_non_face'] = incorrect_non_face_classified\n",
    "                classifier['pred_face'] = pred_face\n",
    "                classifier['pred_non_face'] = pred_non_face\n",
    "\n",
    "            else:\n",
    "                incorrect_face_classify = classifier['miss_clasf_face']\n",
    "                incorrect_non_face_classify = classifier['miss_clasf_non_face']\n",
    "\n",
    "                incorrect_weights_f = np.take(weights_f, incorrect_face_classify)\n",
    "                incorrect_weights_n_f = np.take(weights_n_f, incorrect_non_face_classify)\n",
    "\n",
    "                total_incorrectly_classified_weights = sum(incorrect_weights_f[0]) + sum(incorrect_weights_n_f[0])\n",
    "\n",
    "                classifier['error'] = total_incorrectly_classified_weights\n",
    "                error = total_incorrectly_classified_weights\n",
    "\n",
    "            classifier['alpha'] = calculate_alpha_for_classifier(error)\n",
    "\n",
    "    return strong_classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following will be Training Code Starting Point\n",
    "1. train_face : Faces Directory Name \n",
    "2. train_non_face : Non Faces Directory Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Faces 4\n",
      "Number of Training Non Faces 4\n",
      "Selected One Classifier (1, 2) (0, 0) 2 1 0 0\n",
      "-----------\n",
      "\n",
      "\n",
      "1\n",
      "1\n",
      "-----------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5e6b7f2d4814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;31m# Training Faces and Non Faces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mstrong_classifiers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_adaboost_face_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_faces_sum_pixels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining_non_faces_sum_pixels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlist_of_rectrangle_templates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-f07c8f67086c>\u001b[0m in \u001b[0;36mtrain_adaboost_face_detection\u001b[0;34m(faces, non_faces, list_of_rectrangle_templates, traing_flag, number_of_classifier_to_select)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-----------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights_f\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_faces\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpred_face\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0me1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights_n_f\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_non_faces\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpred_non_face\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "list_of_rectrangle_templates = create_rectangular_filters(24,10,16);\n",
    "training_faces_sum_pixels = all_images_pixel(\"train_face\",0)\n",
    "training_non_faces_sum_pixels = all_images_pixel(\"train_non_face\",0)\n",
    "\n",
    "print(\"Number of Training Faces\",np.size(training_faces_sum_pixels))\n",
    "print(\"Number of Training Non Faces\",np.size(training_non_faces_sum_pixels))\n",
    "\n",
    "# Training Faces and Non Faces\n",
    "strong_classifiers = train_adaboost_face_detection(training_faces_sum_pixels,training_non_faces_sum_pixels,list_of_rectrangle_templates,1,2)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print(stop - start)\n",
    "# Write Weak Hypothesis in  json file\\\n",
    "write_json(strong_classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following code will be for Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_images_pixel(directory_name):\n",
    "    pixel_all_image_in_directory = []\n",
    "    all_image_names = os.listdir(directory_name)\n",
    "\n",
    "    for image_name in all_image_names:\n",
    "        image = cv2.imread(directory_name + \"/\" + image_name);\n",
    "        images = {}\n",
    "        images['image'] = image\n",
    "        images['name'] = image_name\n",
    "        pixel_all_image_in_directory.append(images)\n",
    "\n",
    "    return pixel_all_image_in_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_face(image,classifiers,scales):\n",
    "    faces = []\n",
    "\n",
    "    for scale in scales:\n",
    "        image_face_detect = resize_image(image,scale);\n",
    "        scale_factor = 100/scale\n",
    "        gray_image = cv2.cvtColor(image_face_detect.copy(), cv2.COLOR_BGR2GRAY)\n",
    "        normalized_image = gray_image / 255\n",
    "        width, height = normalized_image.shape\n",
    "\n",
    "        for h in range(0,height):\n",
    "            for w in range(0,width):\n",
    "                #validate weather the index out of bound does not occur\n",
    "                if (w + 24 > width) or (h + 24 > height):\n",
    "                    continue\n",
    "\n",
    "                image_slice = normalized_image[w:w + 24, h:h + 24]\n",
    "                Hx = 0\n",
    "                for classifier in classifiers:\n",
    "                    alpha = classifier['alpha']\n",
    "                    threshold = classifier['threshold']\n",
    "                    w_c = classifier['width']\n",
    "                    h_c = classifier['height']\n",
    "                    n, m = classifier['type']\n",
    "                    x, y = classifier['position']\n",
    "\n",
    "                    filter_window_slice = image_slice[x:x + w_c, y:y + h_c]\n",
    "                    value = each_classifier_size_net_value(filter_window_slice, w_c, h_c, n, m)\n",
    "\n",
    "                    h_x = 0;\n",
    "                    if value >= threshold:\n",
    "                        h_x = 1\n",
    "                    else:\n",
    "                        h_x = -1\n",
    "\n",
    "                    Hx = Hx + (h_x*alpha)\n",
    "\n",
    "                #find out that 24x24 window has face in it\n",
    "                Hx_sign = np.sign(Hx)\n",
    "\n",
    "                if Hx_sign == 1:\n",
    "                    #print(\"Found Face\",w,h)\n",
    "                    face = [int(np.ceil(h*scale_factor)),int(np.ceil(w*scale_factor)),int(np.ceil(24*scale_factor)),int(np.ceil(24*scale_factor)),scale_factor]\n",
    "                    faces.append(face)\n",
    "                    w = w + 24\n",
    "\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_image(image,percentage):\n",
    "    image_r = sc.imresize(image, percentage);\n",
    "    return image_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_redundant_faces(faces):\n",
    "    filtered_faces = []\n",
    "    flag = False\n",
    "\n",
    "    for [x,y,h,w,scale] in faces:\n",
    "\n",
    "        if len(filtered_faces) == 0:\n",
    "            flag = True\n",
    "        else:\n",
    "            for [x1,y1,h1,w1,scale1] in filtered_faces:\n",
    "                if x > x1-15 and x < x1+15:\n",
    "                    flag = False\n",
    "                    break\n",
    "                else:\n",
    "                    flag = True\n",
    "\n",
    "        if flag == True:\n",
    "            face = [x, y, h, w,scale]\n",
    "            filtered_faces.append(face)\n",
    "\n",
    "        flag = False\n",
    "\n",
    "    return filtered_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_rectrangle(name,image,faces):\n",
    "    for [x,y,h,w,scale] in faces:\n",
    "        cv2.rectangle(image, (x,y), (x + w, y + h), (0, 0, 255), lineType=8, thickness=1);\n",
    "\n",
    "    name = name + \"_detected_face.jpg\"\n",
    "    cv2.imwrite(name, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_json(file_name):\n",
    "    with open(file_name) as file:\n",
    "        classifiers = json.load(file)\n",
    "        return classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following code is starting point for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing Faces\n",
    "file_name = \"Nayak_03_02.json\"\n",
    "classifiers = read_json(file_name)\n",
    "testing_images = read_images_pixel(\"Test\")\n",
    "scales = [100,75,50,25,10,8]\n",
    "count = 0\n",
    "for image in testing_images:\n",
    "    start = timeit.default_timer()\n",
    "    img = image['image']\n",
    "    name = image['name']\n",
    "    faces = detect_face(img,classifiers,scales)\n",
    "    filtered_faces = filter_redundant_faces(faces)\n",
    "    draw_rectrangle(name, img, filtered_faces)\n",
    "    end = timeit.default_timer()\n",
    "    print(\"Image \",count,\" Processing Complete in \",end - start,\" sec\")\n",
    "    count = count + 1\n",
    "\n",
    "print(\"Face Detection Completed\")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
